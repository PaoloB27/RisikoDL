{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Import statements"
      ],
      "metadata": {
        "id": "EuGwcYgAAN0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import shutil\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "i7yB6amoAP9J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the drive folder containing all required files"
      ],
      "metadata": {
        "id": "mJm3Ejz2Dw09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# access the drive folder containing everything we need\n",
        "%cd /content/drive/My Drive/Colab environments/Risiko! DL\n",
        "\n",
        "# check that we are in the desired folder\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZjjt0aND9iM",
        "outputId": "93064b18-8822-4f31-db29-263ce897341e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab environments/Risiko! DL\n",
            " \u001b[0m\u001b[01;34m3D_models\u001b[0m/                                'Risiko! Test.ipynb'\n",
            " \u001b[01;34mbackgrounds\u001b[0m/                               \u001b[01;34mruns\u001b[0m/\n",
            " coco_risiko.yaml                           Split_train_test_val.ipynb\n",
            " Complete_tanks_flags_detection.ipynb       \u001b[01;34msynthetic_dataset\u001b[0m/\n",
            " custom_complete_yolo.yaml                  \u001b[01;34msynthetic_images\u001b[0m/\n",
            " custom_yolo.yaml                           tanks_flags_detection.ipynb\n",
            " \u001b[01;34mdatasets\u001b[0m/                                  Test_detection.ipynb\n",
            " \u001b[01;34mpre_trained_weights\u001b[0m/                       test_example.txt\n",
            " \u001b[01;34mreal_images\u001b[0m/                               test.txt\n",
            "'Risiko!_Synthetic_Dataset_Creator.ipynb'   \u001b[01;34myolov5\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load the weights of the models\n",
        "- $exp\\_300\\_epochs$ contains the weights of the model trained using only synthetic images;\n",
        "- $exp\\_complete$ contains the weights of the model trained using both synthetic and real images."
      ],
      "metadata": {
        "id": "6tjM_sU8XDuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generic path to the weights folder\n",
        "weights_folder = 'runs/train'\n",
        "weights_path = os.path.join(os.getcwd(), weights_folder)\n",
        "print(weights_path)\n",
        "\n",
        "# specific path to weigths obtained with 300 epochs on only synthetic images\n",
        "specific_folder_syn = 'exp_300_epochs/weights/best.pt'\n",
        "syn_weights_path = os.path.join(weights_path, specific_folder_syn)\n",
        "print(syn_weights_path)\n",
        "\n",
        "# specific path to weigths obtained with 300 epochs on synthetic and real images\n",
        "specific_folder_compl = 'exp_complete_training/weights/best.pt'\n",
        "compl_weights_path = os.path.join(weights_path, specific_folder_compl)\n",
        "print(compl_weights_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Q_dlvaJFub",
        "outputId": "2d0efb35-1328-451f-91d1-7488d552df10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab environments/Risiko! DL/runs/train\n",
            "/content/drive/My Drive/Colab environments/Risiko! DL/runs/train/exp_300_epochs/weights/best.pt\n",
            "/content/drive/My Drive/Colab environments/Risiko! DL/runs/train/exp_complete_training/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone the GitHub repository yolov5 and install requirements"
      ],
      "metadata": {
        "id": "TRTEeaOKEOKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "x7mTY5zLD_uU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3550b535-b98a-4a80-83dd-26cdfe62b9e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab environments/Risiko! DL\n",
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/drive/My Drive/Colab environments/Risiko! DL/yolov5\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m625.9/625.9 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the models"
      ],
      "metadata": {
        "id": "Sa5qZWunHFdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "\n",
        "# model trained only on synthetic images\n",
        "syn_model = torch.hub.load(os.getcwd(), 'custom', path = syn_weights_path, source ='local', force_reload=True)\n",
        "syn_model.to(device)\n",
        "\n",
        "# model trained only on synthetic images\n",
        "compl_model = torch.hub.load(os.getcwd(), 'custom', path = compl_weights_path, source ='local', force_reload=True)\n",
        "compl_model.to(device)"
      ],
      "metadata": {
        "id": "eMHoHAwkHISA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dda8bae-4f1e-492a-b94a-be272996914e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ 2023-6-11 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7042489 parameters, 0 gradients, 15.9 GFLOPs\n",
            "Adding AutoShape... \n",
            "YOLOv5 ðŸš€ 2023-6-11 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7042489 parameters, 0 gradients, 15.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoShape(\n",
              "  (model): DetectMultiBackend(\n",
              "    (model): DetectionModel(\n",
              "      (model): Sequential(\n",
              "        (0): Conv(\n",
              "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv(\n",
              "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): Conv(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (4): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): Conv(\n",
              "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (6): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): Conv(\n",
              "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (8): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): SPPF(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "        )\n",
              "        (10): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (11): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (12): Concat()\n",
              "        (13): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (14): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (15): Upsample(scale_factor=2.0, mode='nearest')\n",
              "        (16): Concat()\n",
              "        (17): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (18): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (19): Concat()\n",
              "        (20): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (21): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (22): Concat()\n",
              "        (23): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (24): Detect(\n",
              "          (m): ModuleList(\n",
              "            (0): Conv2d(128, 51, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (1): Conv2d(256, 51, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (2): Conv2d(512, 51, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load the paths to the test images and the paths to the labels files"
      ],
      "metadata": {
        "id": "JF97gpa1ak6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the models in evaluation mode\n",
        "syn_model.eval()\n",
        "compl_model.eval()\n",
        "\n",
        "\n",
        "# IMAGES\n",
        "\n",
        "# path to the synthetic dataset\n",
        "syn_path = '/content/drive/My Drive/Colab environments/Risiko! DL/datasets/test/synthetic/images'\n",
        "# path to the real dataset\n",
        "real_path = '/content/drive/My Drive/Colab environments/Risiko! DL/datasets/test/real/images'\n",
        "\n",
        "# Get the lists of files in the directories\n",
        "syn_files = os.listdir(syn_path)\n",
        "real_files = os.listdir(real_path)\n",
        "\n",
        "# create the list of paths to the synthetic test images\n",
        "test_synthetic_images = []\n",
        "\n",
        "for file_name in syn_files:\n",
        "    # full file path\n",
        "    file_path = os.path.join(syn_path, file_name)\n",
        "    # add the image to the list\n",
        "    test_synthetic_images.append(file_path)\n",
        "\n",
        "# create the list of paths to the real test images\n",
        "test_real_images = []\n",
        "\n",
        "for file_name in real_files:\n",
        "    # full file path\n",
        "    file_path = os.path.join(real_path, file_name)\n",
        "    # add the image to the list\n",
        "    test_real_images.append(file_path)\n",
        "\n",
        "\n",
        "# LABELS\n",
        "\n",
        "# paths to the labels\n",
        "syn_labels_path = '/content/drive/My Drive/Colab environments/Risiko! DL/datasets/test/synthetic/labels'\n",
        "real_labels_path = '/content/drive/My Drive/Colab environments/Risiko! DL/datasets/test/real/labels'\n",
        "\n",
        "# get the lists of files in each directory\n",
        "syn_files = os.listdir(syn_labels_path)\n",
        "real_files = os.listdir(real_labels_path)\n",
        "\n",
        "# create the list of synthetic test labels\n",
        "test_synthetic_labels = []\n",
        "\n",
        "for file_name in syn_files:\n",
        "    # full file path\n",
        "    file_path = os.path.join(syn_labels_path, file_name)\n",
        "    # add the image to the list\n",
        "    test_synthetic_labels.append(file_path)\n",
        "\n",
        "# create the list of real test labels\n",
        "test_real_labels = []\n",
        "\n",
        "for file_name in real_files:\n",
        "    # full file path\n",
        "    file_path = os.path.join(real_labels_path, file_name)\n",
        "    # add the image to the list\n",
        "    test_real_labels.append(file_path)"
      ],
      "metadata": {
        "id": "T1hmDvhYapsm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Since the ground truth labels contain the bounding boxes in format [x_center, y_center, width, height], we use the function below to convert them in the format [x_min, y_min, x_max, y_max]"
      ],
      "metadata": {
        "id": "84kzTLvUvJg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the input bbox from [x_center, y_center, width, height] format to\n",
        "# [x_min, y_min, x_max, y_max] format.\n",
        "def convert_bbox(bbox):\n",
        "\n",
        "    x_center = bbox[0]\n",
        "    y_center = bbox[1]\n",
        "    width = bbox[2]\n",
        "    height = bbox[3]\n",
        "\n",
        "    x_min = x_center - width / 2\n",
        "    y_min = y_center - height / 2\n",
        "    x_max = x_center + width / 2\n",
        "    y_max = y_center + height / 2\n",
        "\n",
        "    return [x_min, y_min, x_max, y_max]"
      ],
      "metadata": {
        "id": "bpPj0bx4i05I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Extract bounding boxes and class labels from the files containing the ground truth of the test images"
      ],
      "metadata": {
        "id": "gIQ-2jBnYE8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract bboxes and labels from .txt files.\n",
        "# $labels is the list of file paths to the .txt files.\n",
        "# Return two lists:\n",
        "#   - $true_bboxes containing the bboxes;\n",
        "#   - $true_labels containing the labels.\n",
        "def extract_bboxes_and_labels(labels):\n",
        "\n",
        "    # store the true bboxes values of synthetic images\n",
        "    true_bboxes = []\n",
        "\n",
        "    # store the true class label values of synthetic images\n",
        "    true_labels = []\n",
        "\n",
        "    # iterate over the labels\n",
        "    for label_file in labels:\n",
        "        # open the current file\n",
        "        with open(label_file, \"r\") as f:\n",
        "            # class label values in the current file\n",
        "            current_file_classes = []\n",
        "            # bboxes values in the current file\n",
        "            current_file_bboxes = []\n",
        "\n",
        "            # iterate over the lines: each line is associated with a true instance\n",
        "            for line in f:\n",
        "                # extract values from a line\n",
        "                string_values = line.split()\n",
        "                # append the class value in the current line of the current file\n",
        "                current_file_classes.append(float(string_values[0]))\n",
        "                # values of the bbox in the current line of the current file\n",
        "                bbox = []\n",
        "                for i in range(1, len(string_values)):\n",
        "                    bbox.append(float(string_values[i]))\n",
        "                # convert the bbox format from (x_center, y_center, width, height)\n",
        "                # to (x_min, y_min, x_max, y_max)\n",
        "                conv_bbox = convert_bbox(bbox)\n",
        "                # append the bbox in the current line of the current file\n",
        "                current_file_bboxes.append(conv_bbox)\n",
        "\n",
        "            # append the bboxes related to the current file\n",
        "            true_bboxes.append(current_file_bboxes)\n",
        "            # append the class labels related to the current file\n",
        "            true_labels.append(current_file_classes)\n",
        "\n",
        "    return true_bboxes, true_labels"
      ],
      "metadata": {
        "id": "kQTLbAFk8p5O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the true bboxes values and the true class label values of synthetic images\n",
        "syn_true_bboxes, syn_true_labels = extract_bboxes_and_labels(test_synthetic_labels)\n",
        "\n",
        "# store the true bboxes values and the true class label values of real images\n",
        "real_true_bboxes, real_true_labels = extract_bboxes_and_labels(test_real_labels)"
      ],
      "metadata": {
        "id": "2jfoZ-c_9IlU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inference of the models\n",
        "We compute inference for:\n",
        "- $syn\\_model$ (model trained only with synthetic images) on the test set containing only synthetic images;\n",
        "- $syn\\_model$ (model trained only with synthetic images) on the test set containing only real images;\n",
        "- $compl\\_model$ (model trained with both synthetic and real images) on the test set containing only synthetic images;\n",
        "- $compl\\_model$ (model trained with both synthetic and real images) on the test set containing only real images;\n",
        "- $syn\\_model$ (model trained only with synthetic images) on the whole test set;\n",
        "- $compl\\_model$ (model trained with both synthetic and real images) on the whole test set;"
      ],
      "metadata": {
        "id": "-lFndKRM0Nmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inference on synthetic images of the model trained only on synthetic images\n",
        "results_sm_si = syn_model(test_synthetic_images, size=640)\n",
        "\n",
        "# inference on real images of the model trained only on synthetic images\n",
        "results_sm_ri = syn_model(test_real_images, size=640)\n",
        "\n",
        "# inference on synthetic images of the model trained on both synthetic and real images\n",
        "results_cm_si = compl_model(test_synthetic_images, size=640)\n",
        "\n",
        "# inference on real images of the model trained on both synthetic and real images\n",
        "results_cm_ri = compl_model(test_real_images, size=640)\n",
        "\n",
        "# create complete test set and ground truth\n",
        "test_images = test_synthetic_images + test_real_images\n",
        "true_bb = syn_true_bboxes + real_true_bboxes\n",
        "true_lb = syn_true_labels + real_true_labels\n",
        "\n",
        "# inference on all test images of the model trained on only synthetic images\n",
        "results_sm = syn_model(test_images, size=640)\n",
        "\n",
        "# inference on all test images of the model trained on both synthetic and real images\n",
        "results_cm = compl_model(test_images, size=640)"
      ],
      "metadata": {
        "id": "KpfruLNnCXZy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation measures\n",
        "The evaluation measures that we have decided to compute are:\n",
        "- $class\\_mean\\_IOU$: is the average Intersection Over Union for each class label, considering all images in a given test set;\n",
        "- $mean\\_IOU$: is the mean Intersection Over Union over all class labels, considering all images in a given test set;\n",
        "- $class\\_precision$: precision for a single class label;\n",
        "- $average\\_precision$: is the average of the precisions for each class label;\n",
        "- $class\\_recall$: recall for a single class label;\n",
        "- $average\\_recall$: is the average of the recalls for each class label;\n",
        "- $f1\\_class$: f1 for a single class label;\n",
        "- $average\\_f1$: is the average of the f1 scores for each class label."
      ],
      "metadata": {
        "id": "p5_-RGCFwQ8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Implementation of the evaluation measures"
      ],
      "metadata": {
        "id": "OFN-KXCcxWIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_WIDTH = 1920\n",
        "IMAGES_HEIGHT = 1280\n",
        "\n",
        "# Normalize a bbox in image of size IMAGES_WIDTH x IMAGES_HEIGHT to values in [0, 1].\n",
        "# The bbox must be in format [x_min, y_min, x_max, y_max].\n",
        "# Return the normalized bbox.\n",
        "def normalize_predicted_bbox(bbox):\n",
        "\n",
        "    x_min = bbox[0] / IMAGES_WIDTH\n",
        "    y_min = bbox[1] / IMAGES_HEIGHT\n",
        "    x_max = bbox[2] / IMAGES_WIDTH\n",
        "    y_max = bbox[3] / IMAGES_HEIGHT\n",
        "\n",
        "    return [x_min, y_min, x_max, y_max]\n",
        "\n",
        "\n",
        "# Print all (key, value) pairs in the dictionary $dic.\n",
        "# The dictionary must have float numbers as values.\n",
        "# As a first row, the string $s is printed before the dictionary.\n",
        "def print_dictionary(dic, s):\n",
        "    print(s)\n",
        "    for key in dic.keys():\n",
        "        print(str(key) + \": \" + \"{:.3f}\".format(dic[key]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compute the IOU between bboxes $bbox_1 and $bbox_2.\n",
        "# $bbox_1 and $bbox_2 are in [x_min, y_min, x_max, y_max] format.\n",
        "# Return the IOU between $bbox_1 and $bbox_2.\n",
        "def calculate_iou(bbox_1, bbox_2):\n",
        "\n",
        "    # Compute the intersection coordinates\n",
        "    x_left = max(bbox_1[0], bbox_2[0])\n",
        "    y_top = max(bbox_1[1], bbox_2[1])\n",
        "    x_right = min(bbox_1[2], bbox_2[2])\n",
        "    y_bottom = min(bbox_1[3], bbox_2[3])\n",
        "\n",
        "    # compute the areas of both bounding bboxes\n",
        "    area_bbox_1 = (bbox_1[2] - bbox_1[0] + 1) * (bbox_1[3] - bbox_1[1] + 1)\n",
        "    area_bbox_2 = (bbox_2[2] - bbox_2[0] + 1) * (bbox_2[3] - bbox_2[1] + 1)\n",
        "\n",
        "    # compute the area of the intersection\n",
        "    intersection_area = max(0, (x_right - x_left + 1)) * max(0, (y_bottom - y_top + 1))\n",
        "\n",
        "    # calculate the IOU\n",
        "    return intersection_area / float(area_bbox_1 + area_bbox_2 - intersection_area)\n",
        "\n",
        "\n",
        "# Compute the mean IOU for each class between predicted bboxes and true ones in a given image.\n",
        "# $predicted_bboxes: predicted bboxes in the image.\n",
        "# $true_bboxes: ground truth bboxes in the image.\n",
        "# $predicted_classes: predicted class labels for each bbox in the image.\n",
        "# $true_classes: true class labels of true bboxes in the image.\n",
        "# Return a dictionary $class_mean_IOU with classes as keys and mean IOU score for that class in the image.\n",
        "def class_mean_IOU_image(predicted_bboxes, true_bboxes, predicted_classes, true_classes):\n",
        "\n",
        "    # dictionary where each key is a class label and the value is the list of IOU for that label\n",
        "    class_IOU_list = {}\n",
        "\n",
        "    # iterate over the predicted bboxes\n",
        "    for i in range(len(predicted_bboxes)):\n",
        "\n",
        "        # list of IOU scores between the current predicted bbox and all the true bboxes with the same class\n",
        "        current_bbox_IOU_scores = []\n",
        "\n",
        "        # class label of the current predicted bbox\n",
        "        predicted_class = predicted_classes[i].tolist()\n",
        "\n",
        "        # initialize the entry of the dictionary\n",
        "        class_IOU_list[predicted_class] = []\n",
        "\n",
        "        # iterate over the true bboxes to compute the IOU scores for the current predicted bbox\n",
        "        for j in range(len(true_bboxes)):\n",
        "            if predicted_class == true_classes[j]:\n",
        "                current_bbox_IOU_scores.append(\n",
        "                    calculate_iou(normalize_predicted_bbox(predicted_bboxes[i].tolist()), true_bboxes[j]))\n",
        "        if len(current_bbox_IOU_scores) > 0:\n",
        "            class_IOU_list[predicted_class].append(np.max(current_bbox_IOU_scores))\n",
        "        else:\n",
        "            class_IOU_list[predicted_class].append(0)\n",
        "\n",
        "    # dictionary where each class label is a key and the associated value is the mean IOU with that label\n",
        "    class_mean_IOU = {}\n",
        "\n",
        "    # fill the dictionary\n",
        "    for class_label in class_IOU_list.keys():\n",
        "        class_mean_IOU[class_label] = np.mean(class_IOU_list[class_label])\n",
        "\n",
        "    return class_mean_IOU\n",
        "\n",
        "\n",
        "# Compute the mean IOU for each class between predicted bboxes and true ones for a dataset of images.\n",
        "# $results is the result of the application of yolov5 model to a batch of images.\n",
        "# $true_bboxes: ground truth bboxes. $true_bboxes[i] contains true bboxes in image $i in the batch of images.\n",
        "# $true_classes: true class labels of true bboxes. $true_classes[i] contains the class label of $true_bboxes[i].\n",
        "# Return a dictionary $class_mean_IOU with classes as keys and mean IOU score for that class in the set of images.\n",
        "def class_mean_IOU(results, true_bboxes, true_classes):\n",
        "\n",
        "    # dictionary with class labels as keys and the corresponding lists of IOU scores as values\n",
        "    IOU_scores = {}\n",
        "\n",
        "    # iterate over the images\n",
        "    for i in range(len(results.xyxy)):\n",
        "\n",
        "        # result of inference on image $i in the batch\n",
        "        predictions = results.xyxy[i]\n",
        "        # predicted bboxes\n",
        "        pred_boxes = predictions[:, :4] # [xmin, ymin, xmax, ymax] for each bbox\n",
        "        # corresponding predicted class labels\n",
        "        pred_labels = predictions[:, 5] # label for each prediction in the image\n",
        "\n",
        "        # dictionary of mean IOU values for the current image\n",
        "        current_image_IOU = class_mean_IOU_image(pred_boxes, true_bboxes[i], pred_labels, true_classes[i])\n",
        "\n",
        "        # iterate over the dictionary to fill the global list\n",
        "        for class_label in current_image_IOU.keys():\n",
        "            if class_label not in IOU_scores:\n",
        "                IOU_scores[class_label] = []\n",
        "            IOU_scores[class_label].append(current_image_IOU[class_label])\n",
        "\n",
        "    # compute the mean IOU for each class and return it\n",
        "    class_mean_IOU = {}\n",
        "    for class_label in IOU_scores.keys():\n",
        "        class_mean_IOU[class_label] = np.mean(IOU_scores[class_label])\n",
        "\n",
        "    return class_mean_IOU\n",
        "\n",
        "\n",
        "# Compute the mean IOU, considering all class mean IOU values.\n",
        "# $classes_mean_IOU is the dictionary containing the class labels as keys and related class mean IOU as value.\n",
        "# Return the value $mean_IOU: mean IOU considering each class mean IOU.\n",
        "def mean_IOU(classes_mean_IOU):\n",
        "\n",
        "    # sum IOU over all classes\n",
        "    sum_IOU = 0\n",
        "\n",
        "    # number of labels\n",
        "    num_classes = 0\n",
        "\n",
        "    # iterate over the dictionary\n",
        "    for class_label in classes_mean_IOU.keys():\n",
        "        sum_IOU += classes_mean_IOU[class_label]\n",
        "        num_classes += 1\n",
        "\n",
        "    return sum_IOU / num_classes\n",
        "\n",
        "\n",
        "# Compute the true positives and false positives for each class.\n",
        "# $results is the result of the application of the yolov5 model to a batch of images.\n",
        "# $true_bboxes: ground truth bboxes of a batch of images.\n",
        "# $true_classes: true class labels of true bboxes.\n",
        "# $conf_thr is the confidence threshold.\n",
        "# $iou_thr is the IOU threshold.\n",
        "# Return two dictionaries:\n",
        "#   - $class_tp_dic contains the number of true positives for each class;\n",
        "#   - $class_fp_dic contains the number of false positives for each class.\n",
        "def class_tp_fp(results, true_bboxes, true_classes, conf_thr=0.7, iou_thr=0.5):\n",
        "\n",
        "    # dictionary where each key is a class label and the value is the number of true positives of that class\n",
        "    # in the image\n",
        "    class_tp_dic = {}\n",
        "    # dictionary where each key is a class label and the value is the number of false positives of that class\n",
        "    # in the image\n",
        "    class_fp_dic = {}\n",
        "\n",
        "    # iterate over the images\n",
        "    for i in range(len(results.xyxy)):\n",
        "\n",
        "        # result of inference on image $i in the batch\n",
        "        predictions = results.xyxy[i]\n",
        "        # predicted bboxes\n",
        "        pred_bboxes = predictions[:, :4] # [xmin, ymin, xmax, ymax] for each bbox\n",
        "        # corresponding confidence scores\n",
        "        confidence_scores = predictions[:, 4]\n",
        "        # corresponding predicted class labels\n",
        "        predicted_classes = predictions[:, 5] # label for each prediction in the image\n",
        "\n",
        "        # iterate over the predicted bboxes in the current image\n",
        "        for j in range(len(pred_bboxes)):\n",
        "\n",
        "            # list of IOU scores between the current predicted bbox and all the true bboxes with the same class\n",
        "            current_bbox_IOU_scores = []\n",
        "\n",
        "            # class label of the current predicted bbox\n",
        "            predicted_class = predicted_classes[j].tolist()\n",
        "\n",
        "            # initialize the dictionaries entries if they have not been added to the dictionaries yet\n",
        "            if predicted_class not in class_tp_dic:\n",
        "                class_tp_dic[predicted_class] = 0\n",
        "            if predicted_class not in class_fp_dic:\n",
        "                class_fp_dic[predicted_class] = 0\n",
        "\n",
        "            # iterate over the true bboxes to compute the IOU scores for the current predicted bbox\n",
        "            for k in range(len(true_bboxes[i])):\n",
        "                if predicted_class == true_classes[i][k]:\n",
        "                    current_bbox_IOU_scores.append(\n",
        "                        calculate_iou(normalize_predicted_bbox(pred_bboxes[j].tolist()), true_bboxes[i][k]))\n",
        "\n",
        "            # check if the current predicted bbox is a false positive or a true positive\n",
        "            if len(current_bbox_IOU_scores) > 0:\n",
        "                if confidence_scores[j] >= conf_thr and np.max(current_bbox_IOU_scores) >= iou_thr:\n",
        "                    class_tp_dic[predicted_class] += 1\n",
        "                else:\n",
        "                    class_fp_dic[predicted_class] += 1\n",
        "            else:\n",
        "                    class_fp_dic[predicted_class] += 1\n",
        "\n",
        "    return class_tp_dic, class_fp_dic\n",
        "\n",
        "# Compute the precision for each class.\n",
        "# $tp_dic is a dictionary containing as keys the class labels and the true positives for that class label as value.\n",
        "# $fp_dic is a dictionary containing as keys the class labels and the false positives for that class label as value.\n",
        "# Return a dictionary with class labels as keys and related class precisions as values.\n",
        "def class_precision(tp_dic, fp_dic):\n",
        "\n",
        "    precision_dic = {}\n",
        "\n",
        "    # iterate over the classes in the dictionaries\n",
        "    for class_label in tp_dic.keys():\n",
        "        precision_dic[class_label] = tp_dic[class_label] / (tp_dic[class_label] + fp_dic[class_label])\n",
        "\n",
        "    return precision_dic\n",
        "\n",
        "\n",
        "# Compute the average precision, taking into account all classes.\n",
        "# $tp_dic is a dictionary containing as keys the class labels and the true positives for that class label as value.\n",
        "# $fn_dic is a dictionary containing as keys the class labels and the false negatives for that class label as value.\n",
        "# Return the average precision.\n",
        "def average_precision(tp_dic, fp_dic):\n",
        "\n",
        "    # overall number of tp taking into account all classes\n",
        "    sum_tp = 0\n",
        "    # overall number of positives taking into account all classes\n",
        "    sum_pred_positives = 0\n",
        "\n",
        "    # iterate over the dictionaries\n",
        "    for class_label in tp_dic.keys():\n",
        "        sum_tp += tp_dic[class_label]\n",
        "        sum_pred_positives += tp_dic[class_label] + fp_dic[class_label]\n",
        "\n",
        "    return sum_tp / sum_pred_positives\n",
        "\n",
        "\n",
        "# Compute the true positives for each class.\n",
        "# $results is the result of the application of the yolov5 model to a batch of images.\n",
        "# $true_bboxes: ground truth bboxes of a batch of images.\n",
        "# $true_classes: true class labels of true bboxes.\n",
        "# $conf_thr is the confidence threshold.\n",
        "# $iou_thr is the IOU threshold.\n",
        "# Return the dictionary $class_tp_dic, which contains the number of true positives for each class.\n",
        "def class_tp(results, true_bboxes, true_classes, conf_thr=0.7, iou_thr=0.5):\n",
        "\n",
        "    # dictionary where each key is a class label and the value is the number of true positives of that class\n",
        "    # in the image\n",
        "    class_tp_dic = {}\n",
        "\n",
        "    # iterate over the images\n",
        "    for i in range(len(results.xyxy)):\n",
        "\n",
        "        # result of inference on image $i in the batch\n",
        "        predictions = results.xyxy[i]\n",
        "        # predicted bboxes\n",
        "        pred_bboxes = predictions[:, :4] # [xmin, ymin, xmax, ymax] for each bbox\n",
        "        # corresponding confidence scores\n",
        "        confidence_scores = predictions[:, 4]\n",
        "        # corresponding predicted class labels\n",
        "        predicted_classes = predictions[:, 5] # label for each prediction in the image\n",
        "\n",
        "        # iterate over the predicted bboxes in the current image\n",
        "        for j in range(len(pred_bboxes)):\n",
        "\n",
        "            # list of IOU scores between the current predicted bbox and all the true bboxes with the same class\n",
        "            current_bbox_IOU_scores = []\n",
        "\n",
        "            # class label of the current predicted bbox\n",
        "            predicted_class = predicted_classes[j].tolist()\n",
        "\n",
        "            # initialize the dictionary entry if it has not been added yet\n",
        "            if predicted_class not in class_tp_dic:\n",
        "                class_tp_dic[predicted_class] = 0\n",
        "\n",
        "            # iterate over the true bboxes to compute the IOU scores for the current predicted bbox\n",
        "            for k in range(len(true_bboxes[i])):\n",
        "                if predicted_class == true_classes[i][k]:\n",
        "                    current_bbox_IOU_scores.append(\n",
        "                        calculate_iou(normalize_predicted_bbox(pred_bboxes[j].tolist()), true_bboxes[i][k]))\n",
        "\n",
        "            # check if the current predicted bbox is a true positive\n",
        "            if len(current_bbox_IOU_scores) > 0:\n",
        "                if confidence_scores[j] >= conf_thr and np.max(current_bbox_IOU_scores) >= iou_thr:\n",
        "                    class_tp_dic[predicted_class] += 1\n",
        "\n",
        "    return class_tp_dic\n",
        "\n",
        "\n",
        "# Compute the false negatives for each class.\n",
        "# $results is the result of the application of the yolov5 model to a batch of images.\n",
        "# $true_bboxes: ground truth bboxes of a batch of images.\n",
        "# $true_classes: true class labels of true bboxes.\n",
        "# Return the dictionary $class_fn_dic, which contains the number of false negatives for each class.\n",
        "def class_fn(results, true_bboxes, true_classes, conf_thr=0.7, iou_thr=0.5):\n",
        "\n",
        "    # dictionary where each key is a class label and the value is the number of false negatives of that class\n",
        "    # in the image\n",
        "    class_fn_dic = {}\n",
        "\n",
        "    # iterate over the images\n",
        "    for i in range(len(results.xyxy)):\n",
        "\n",
        "        # result of inference on image $i in the batch\n",
        "        predictions = results.xyxy[i]\n",
        "        # predicted bboxes\n",
        "        pred_bboxes = predictions[:, :4] # [xmin, ymin, xmax, ymax] for each bbox\n",
        "        # corresponding confidence scores\n",
        "        confidence_scores = predictions[:, 4]\n",
        "        # corresponding predicted class labels\n",
        "        predicted_classes = predictions[:, 5] # label for each prediction in the image\n",
        "\n",
        "        # iterate over the true bboxes in the current image\n",
        "        for j in range(len(true_bboxes[i])):\n",
        "\n",
        "            # list of IOU scores between the current true bbox and all the predicted bboxes with the same class\n",
        "            current_bbox_IOU_scores = []\n",
        "\n",
        "            # class label of the current true bbox\n",
        "            true_class = true_classes[i][j]\n",
        "\n",
        "            # initialize the dictionary entry if it has not been added yet\n",
        "            if true_class not in class_fn_dic:\n",
        "                class_fn_dic[true_class] = 0\n",
        "\n",
        "            # iterate over the predicted bboxes to compute the IOU scores with the current true bbox\n",
        "            for k in range(len(pred_bboxes.tolist())):\n",
        "                if true_class == predicted_classes[k].tolist():\n",
        "                    current_bbox_IOU_scores.append(\n",
        "                        calculate_iou(normalize_predicted_bbox(pred_bboxes[k].tolist()), true_bboxes[i][j]))\n",
        "\n",
        "            # check if the current predicted bbox is a false negative\n",
        "            if len(current_bbox_IOU_scores) != 0:\n",
        "                if (confidence_scores[np.argmax(current_bbox_IOU_scores)] < conf_thr or\n",
        "                    np.max(current_bbox_IOU_scores) < iou_thr):\n",
        "                    class_fn_dic[true_class] += 1\n",
        "            else:\n",
        "                class_fn_dic[true_class] += 1\n",
        "\n",
        "    return class_fn_dic\n",
        "\n",
        "\n",
        "# Compute the recall for each class.\n",
        "# $tp_dic is a dictionary containing as keys the class labels and the true positives for that class label as value.\n",
        "# $fn_dic is a dictionary containing as keys the class labels and the false negatives for that class label as value.\n",
        "# Return a dictionary with class labels as keys and related class recalls as values.\n",
        "def class_recall(tp_dic, fn_dic):\n",
        "\n",
        "    recall_dic = {}\n",
        "\n",
        "    # iterate over the classes in the dictionaries\n",
        "    for class_label in tp_dic.keys():\n",
        "        recall_dic[class_label] = tp_dic[class_label] / (tp_dic[class_label] + fn_dic[class_label])\n",
        "\n",
        "    return recall_dic\n",
        "\n",
        "\n",
        "# Compute the average recall, taking into account all classes.\n",
        "# $tp_dic is a dictionary containing as keys the class labels and the true positives for that class label as value.\n",
        "# $fn_dic is a dictionary containing as keys the class labels and the false negatives for that class label as value.\n",
        "# Return the average recall.\n",
        "def average_recall(tp_dic, fn_dic):\n",
        "\n",
        "    # overall number of tp taking into account all classes\n",
        "    sum_tp = 0\n",
        "    # overall number of real positives taking into account all classes\n",
        "    sum_real_positives = 0\n",
        "\n",
        "    # iterate over the dictionaries\n",
        "    for class_label in tp_dic.keys():\n",
        "        sum_tp += tp_dic[class_label]\n",
        "        sum_real_positives += tp_dic[class_label] + fn_dic[class_label]\n",
        "\n",
        "    return sum_tp / sum_real_positives\n",
        "\n",
        "\n",
        "# Compute the f1 score for each class.\n",
        "# $class_precision is a dictionary containing precision for each class.\n",
        "# $class_recall is a dictionary containing recall for each class.\n",
        "# Return a dictionary with the f1 score for each class.\n",
        "def class_f1(class_precision, class_recall):\n",
        "\n",
        "    # dictionary with class labels as keys and class f1 scores as values\n",
        "    class_f1 = {}\n",
        "\n",
        "    # fill the dictionary\n",
        "    for label in class_precision.keys():\n",
        "        if class_precision[label] != 0 and class_recall[label] != 0:\n",
        "            class_f1[label] = 2 * class_precision[label] * class_recall[label] / (class_precision[label] + class_recall[label])\n",
        "        else:\n",
        "            class_f1[label] = 0\n",
        "\n",
        "\n",
        "    # return the dictionary\n",
        "    return class_f1\n",
        "\n",
        "def mean_f1(class_f1):\n",
        "\n",
        "    # sum of f1 scores\n",
        "    f1 = 0\n",
        "    # number of classes\n",
        "    classes = 0\n",
        "\n",
        "    # iterate over the classes\n",
        "    for label in class_f1.keys():\n",
        "        f1 += class_f1[label]\n",
        "        classes +=1\n",
        "\n",
        "    # return the mean f1 over all classes\n",
        "    return f1 / classes\n",
        "\n",
        "\n",
        "# Function that applies the above evaluations and prints them.\n",
        "# $string_print contains information to be printed before the results.\n",
        "# $true_bboxes: ground truth bboxes of a batch of images.\n",
        "# $true_classes: true class labels of true bboxes.\n",
        "def evaluate_and_print(string_print, results, true_bboxes, true_labels):\n",
        "\n",
        "    # print information regarding the model\n",
        "    print()\n",
        "    print(\"-\" * 50)\n",
        "    print(\"\\n\" + string_print)\n",
        "\n",
        "    # compute the class mean IOU\n",
        "    class_mean_iou = class_mean_IOU(results, true_bboxes, true_labels)\n",
        "    # sort the dictionary by key, i.e. by class\n",
        "    class_mean_iou = dict(sorted(class_mean_iou.items()))\n",
        "    print_dictionary(class_mean_iou, \"Mean IOU for each class:\")\n",
        "\n",
        "    mean_iou = mean_IOU(class_mean_iou)\n",
        "    print(\"\\nMean IOU over all classes: \" + \"{:.3f}\".format(mean_iou))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "    # true positives and false positives for each class\n",
        "    cl_tp, cl_fp = class_tp_fp(results, true_bboxes, true_labels)\n",
        "\n",
        "    # sort the dictionaries by key, i.e. by class\n",
        "    cl_tp = dict(sorted(cl_tp.items()))\n",
        "    cl_fp = dict(sorted(cl_fp.items()))\n",
        "\n",
        "    # compute precision for each class\n",
        "    class_prec = class_precision(cl_tp, cl_fp)\n",
        "    print_dictionary(class_prec, \"Precision for each class:\")\n",
        "\n",
        "    # compute average precision over all classes\n",
        "    av_precision = average_precision(cl_tp, cl_fp)\n",
        "    print(\"\\nAverage precision over all classes: \" + \"{:.3f}\".format(av_precision))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "    # compute true positives and false negatives\n",
        "    cl_tp = class_tp(results, true_bboxes, true_labels)\n",
        "    cl_fn = class_fn(results, true_bboxes, true_labels)\n",
        "\n",
        "    # sort the dictionaries by key, i.e. by class\n",
        "    cl_tp = dict(sorted(cl_tp.items()))\n",
        "    cl_fn = dict(sorted(cl_fn.items()))\n",
        "\n",
        "    # compute recall for each class\n",
        "    class_rec = class_recall(cl_tp, cl_fn)\n",
        "    print_dictionary(class_rec, \"Recall for each class:\")\n",
        "\n",
        "    # compute average recall\n",
        "    av_recall = average_recall(cl_tp, cl_fn)\n",
        "    print(\"\\nAverage recall over all classes: \" + \"{:.3f}\".format(av_recall))\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "    # compute f1 score for each class\n",
        "    f1_class = class_f1(class_prec, class_rec)\n",
        "    print_dictionary(f1_class, \"F1 score for each class:\")\n",
        "\n",
        "    # compute average f1 score\n",
        "    f1 = mean_f1(f1_class)\n",
        "    print(\"\\nAverage F1 score over all classes: \" + \"{:.3f}\".format(f1))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "1dtOVmBpvLQ-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Application of the above evaluation measures to all the inference results (different models on synthetic and real test sets)"
      ],
      "metadata": {
        "id": "ciGYrCntxBq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL TRAINED ON SYNTHETIC IMAGES: SYNTHETIC TEST SET\n",
        "str_pr = \"MODEL TRAINED ON SYNTHETIC IMAGES: SYNTHETIC TEST SET\"\n",
        "evaluate_and_print(str_pr, results_sm_si, syn_true_bboxes, syn_true_labels)\n",
        "\n",
        "# MODEL TRAINED ON SYNTHETIC IMAGES: REAL TEST SET\n",
        "str_pr = \"MODEL TRAINED ON SYNTHETIC IMAGES: REAL TEST SET\"\n",
        "evaluate_and_print(str_pr, results_sm_ri, real_true_bboxes, real_true_labels)\n",
        "\n",
        "# MODEL TRAINED ON ALL IMAGES: SYNTHETIC TEST SET\n",
        "str_pr = \"MODEL TRAINED ON ALL IMAGES: SYNTHETIC TEST SET\"\n",
        "evaluate_and_print(str_pr, results_cm_si, syn_true_bboxes, syn_true_labels)\n",
        "\n",
        "# MODEL TRAINED ON ALL IMAGES: REAL TEST SET\n",
        "str_pr = \"MODEL TRAINED ON ALL IMAGES: REAL TEST SET\"\n",
        "evaluate_and_print(str_pr, results_cm_ri, real_true_bboxes, real_true_labels)\n",
        "\n",
        "# MODEL TRAINED ONLY ON SYNTHETIC IMAGES: COMPLETE TEST SET\n",
        "str_pr = \"MODEL TRAINED ONLY ON SYNTHETIC IMAGES: COMPLETE TEST SET\"\n",
        "evaluate_and_print(str_pr, results_sm, true_bb, true_lb)\n",
        "\n",
        "# MODEL TRAINED ON ALL IMAGES: COMPLETE TEST SET\n",
        "str_pr = \"MODEL TRAINED ON ALL IMAGES: COMPLETE TEST SET\"\n",
        "evaluate_and_print(str_pr, results_cm, true_bb, true_lb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am-WCj15xNsF",
        "outputId": "58bf3811-cbfa-429b-d935-40620f26714e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "MODEL TRAINED ON SYNTHETIC IMAGES: SYNTHETIC TEST SET\n",
            "Mean IOU for each class:\n",
            "0.0: 0.951\n",
            "1.0: 0.964\n",
            "2.0: 0.951\n",
            "3.0: 0.956\n",
            "4.0: 0.935\n",
            "5.0: 0.953\n",
            "6.0: 0.944\n",
            "7.0: 0.964\n",
            "8.0: 0.954\n",
            "9.0: 0.953\n",
            "10.0: 0.897\n",
            "11.0: 0.986\n",
            "\n",
            "Mean IOU over all classes: 0.951\n",
            "\n",
            "\n",
            "Precision for each class:\n",
            "0.0: 0.792\n",
            "1.0: 0.821\n",
            "2.0: 0.778\n",
            "3.0: 0.775\n",
            "4.0: 0.760\n",
            "5.0: 0.804\n",
            "6.0: 0.831\n",
            "7.0: 0.814\n",
            "8.0: 0.809\n",
            "9.0: 0.799\n",
            "10.0: 0.743\n",
            "11.0: 0.827\n",
            "\n",
            "Average precision over all classes: 0.791\n",
            "\n",
            "\n",
            "Recall for each class:\n",
            "0.0: 1.000\n",
            "1.0: 0.998\n",
            "2.0: 0.997\n",
            "3.0: 0.997\n",
            "4.0: 0.998\n",
            "5.0: 0.999\n",
            "6.0: 0.989\n",
            "7.0: 0.991\n",
            "8.0: 0.985\n",
            "9.0: 0.978\n",
            "10.0: 0.973\n",
            "11.0: 0.991\n",
            "\n",
            "Average recall over all classes: 0.995\n",
            "\n",
            "\n",
            "F1 score for each class:\n",
            "0.0: 0.884\n",
            "1.0: 0.901\n",
            "2.0: 0.874\n",
            "3.0: 0.872\n",
            "4.0: 0.863\n",
            "5.0: 0.891\n",
            "6.0: 0.903\n",
            "7.0: 0.894\n",
            "8.0: 0.889\n",
            "9.0: 0.880\n",
            "10.0: 0.843\n",
            "11.0: 0.902\n",
            "\n",
            "Average F1 score over all classes: 0.883\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "MODEL TRAINED ON SYNTHETIC IMAGES: REAL TEST SET\n",
            "Mean IOU for each class:\n",
            "0.0: 0.488\n",
            "1.0: 0.331\n",
            "2.0: 0.492\n",
            "3.0: 0.439\n",
            "4.0: 0.345\n",
            "5.0: 0.354\n",
            "6.0: 0.601\n",
            "7.0: 0.396\n",
            "8.0: 0.256\n",
            "9.0: 0.259\n",
            "10.0: 0.266\n",
            "11.0: 0.395\n",
            "\n",
            "Mean IOU over all classes: 0.385\n",
            "\n",
            "\n",
            "Precision for each class:\n",
            "0.0: 0.067\n",
            "1.0: 0.110\n",
            "2.0: 0.146\n",
            "3.0: 0.000\n",
            "4.0: 0.083\n",
            "5.0: 0.200\n",
            "6.0: 0.105\n",
            "7.0: 0.000\n",
            "8.0: 0.000\n",
            "9.0: 0.000\n",
            "10.0: 0.000\n",
            "11.0: 0.000\n",
            "\n",
            "Average precision over all classes: 0.101\n",
            "\n",
            "\n",
            "Recall for each class:\n",
            "0.0: 0.021\n",
            "1.0: 0.062\n",
            "2.0: 0.025\n",
            "3.0: 0.000\n",
            "4.0: 0.010\n",
            "5.0: 0.060\n",
            "6.0: 0.040\n",
            "7.0: 0.000\n",
            "8.0: 0.000\n",
            "9.0: 0.000\n",
            "10.0: 0.000\n",
            "11.0: 0.000\n",
            "\n",
            "Average recall over all classes: 0.025\n",
            "\n",
            "\n",
            "F1 score for each class:\n",
            "0.0: 0.032\n",
            "1.0: 0.079\n",
            "2.0: 0.043\n",
            "3.0: 0.000\n",
            "4.0: 0.018\n",
            "5.0: 0.092\n",
            "6.0: 0.058\n",
            "7.0: 0.000\n",
            "8.0: 0.000\n",
            "9.0: 0.000\n",
            "10.0: 0.000\n",
            "11.0: 0.000\n",
            "\n",
            "Average F1 score over all classes: 0.027\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "MODEL TRAINED ON ALL IMAGES: SYNTHETIC TEST SET\n",
            "Mean IOU for each class:\n",
            "0.0: 0.949\n",
            "1.0: 0.952\n",
            "2.0: 0.948\n",
            "3.0: 0.963\n",
            "4.0: 0.927\n",
            "5.0: 0.964\n",
            "6.0: 0.970\n",
            "7.0: 0.972\n",
            "8.0: 0.967\n",
            "9.0: 0.942\n",
            "10.0: 0.912\n",
            "11.0: 0.976\n",
            "\n",
            "Mean IOU over all classes: 0.953\n",
            "\n",
            "\n",
            "Precision for each class:\n",
            "0.0: 0.798\n",
            "1.0: 0.799\n",
            "2.0: 0.776\n",
            "3.0: 0.776\n",
            "4.0: 0.743\n",
            "5.0: 0.803\n",
            "6.0: 0.847\n",
            "7.0: 0.833\n",
            "8.0: 0.805\n",
            "9.0: 0.794\n",
            "10.0: 0.740\n",
            "11.0: 0.849\n",
            "\n",
            "Average precision over all classes: 0.788\n",
            "\n",
            "\n",
            "Recall for each class:\n",
            "0.0: 1.000\n",
            "1.0: 0.998\n",
            "2.0: 0.998\n",
            "3.0: 0.999\n",
            "4.0: 0.999\n",
            "5.0: 0.999\n",
            "6.0: 0.989\n",
            "7.0: 0.978\n",
            "8.0: 0.992\n",
            "9.0: 0.978\n",
            "10.0: 0.982\n",
            "11.0: 0.987\n",
            "\n",
            "Average recall over all classes: 0.996\n",
            "\n",
            "\n",
            "F1 score for each class:\n",
            "0.0: 0.887\n",
            "1.0: 0.887\n",
            "2.0: 0.873\n",
            "3.0: 0.874\n",
            "4.0: 0.852\n",
            "5.0: 0.890\n",
            "6.0: 0.913\n",
            "7.0: 0.900\n",
            "8.0: 0.889\n",
            "9.0: 0.876\n",
            "10.0: 0.844\n",
            "11.0: 0.913\n",
            "\n",
            "Average F1 score over all classes: 0.883\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "MODEL TRAINED ON ALL IMAGES: REAL TEST SET\n",
            "Mean IOU for each class:\n",
            "0.0: 0.453\n",
            "1.0: 0.530\n",
            "2.0: 0.892\n",
            "4.0: 0.689\n",
            "5.0: 0.778\n",
            "6.0: 0.522\n",
            "7.0: 0.246\n",
            "11.0: 0.824\n",
            "\n",
            "Mean IOU over all classes: 0.617\n",
            "\n",
            "\n",
            "Precision for each class:\n",
            "0.0: 0.000\n",
            "1.0: 0.240\n",
            "2.0: 0.000\n",
            "4.0: 0.000\n",
            "5.0: 0.538\n",
            "6.0: 0.000\n",
            "7.0: 0.000\n",
            "11.0: 0.000\n",
            "\n",
            "Average precision over all classes: 0.151\n",
            "\n",
            "\n",
            "Recall for each class:\n",
            "0.0: 0.000\n",
            "1.0: 0.027\n",
            "2.0: 0.000\n",
            "4.0: 0.000\n",
            "5.0: 0.035\n",
            "6.0: 0.000\n",
            "7.0: 0.000\n",
            "11.0: 0.000\n",
            "\n",
            "Average recall over all classes: 0.009\n",
            "\n",
            "\n",
            "F1 score for each class:\n",
            "0.0: 0.000\n",
            "1.0: 0.049\n",
            "2.0: 0.000\n",
            "4.0: 0.000\n",
            "5.0: 0.065\n",
            "6.0: 0.000\n",
            "7.0: 0.000\n",
            "11.0: 0.000\n",
            "\n",
            "Average F1 score over all classes: 0.014\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "MODEL TRAINED ONLY ON SYNTHETIC IMAGES: COMPLETE TEST SET\n",
            "Mean IOU for each class:\n",
            "0.0: 0.917\n",
            "1.0: 0.919\n",
            "2.0: 0.928\n",
            "3.0: 0.940\n",
            "4.0: 0.911\n",
            "5.0: 0.908\n",
            "6.0: 0.927\n",
            "7.0: 0.944\n",
            "8.0: 0.931\n",
            "9.0: 0.942\n",
            "10.0: 0.873\n",
            "11.0: 0.976\n",
            "\n",
            "Mean IOU over all classes: 0.926\n",
            "\n",
            "\n",
            "Precision for each class:\n",
            "0.0: 0.731\n",
            "1.0: 0.767\n",
            "2.0: 0.756\n",
            "3.0: 0.765\n",
            "4.0: 0.739\n",
            "5.0: 0.776\n",
            "6.0: 0.793\n",
            "7.0: 0.796\n",
            "8.0: 0.792\n",
            "9.0: 0.794\n",
            "10.0: 0.723\n",
            "11.0: 0.816\n",
            "\n",
            "Average precision over all classes: 0.761\n",
            "\n",
            "\n",
            "Recall for each class:\n",
            "0.0: 0.737\n",
            "1.0: 0.856\n",
            "2.0: 0.778\n",
            "3.0: 0.835\n",
            "4.0: 0.758\n",
            "5.0: 0.848\n",
            "6.0: 0.838\n",
            "7.0: 0.875\n",
            "8.0: 0.928\n",
            "9.0: 0.864\n",
            "10.0: 0.856\n",
            "11.0: 0.935\n",
            "\n",
            "Average recall over all classes: 0.815\n",
            "\n",
            "\n",
            "F1 score for each class:\n",
            "0.0: 0.734\n",
            "1.0: 0.809\n",
            "2.0: 0.767\n",
            "3.0: 0.798\n",
            "4.0: 0.748\n",
            "5.0: 0.810\n",
            "6.0: 0.815\n",
            "7.0: 0.834\n",
            "8.0: 0.855\n",
            "9.0: 0.827\n",
            "10.0: 0.784\n",
            "11.0: 0.871\n",
            "\n",
            "Average F1 score over all classes: 0.804\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "MODEL TRAINED ON ALL IMAGES: COMPLETE TEST SET\n",
            "Mean IOU for each class:\n",
            "0.0: 0.943\n",
            "1.0: 0.946\n",
            "2.0: 0.947\n",
            "3.0: 0.961\n",
            "4.0: 0.923\n",
            "5.0: 0.964\n",
            "6.0: 0.955\n",
            "7.0: 0.967\n",
            "8.0: 0.967\n",
            "9.0: 0.944\n",
            "10.0: 0.914\n",
            "11.0: 0.975\n",
            "\n",
            "Mean IOU over all classes: 0.950\n",
            "\n",
            "\n",
            "Precision for each class:\n",
            "0.0: 0.781\n",
            "1.0: 0.786\n",
            "2.0: 0.774\n",
            "3.0: 0.776\n",
            "4.0: 0.742\n",
            "5.0: 0.800\n",
            "6.0: 0.816\n",
            "7.0: 0.830\n",
            "8.0: 0.796\n",
            "9.0: 0.791\n",
            "10.0: 0.746\n",
            "11.0: 0.839\n",
            "\n",
            "Average precision over all classes: 0.782\n",
            "\n",
            "\n",
            "Recall for each class:\n",
            "0.0: 0.709\n",
            "1.0: 0.808\n",
            "2.0: 0.762\n",
            "3.0: 0.813\n",
            "4.0: 0.749\n",
            "5.0: 0.831\n",
            "6.0: 0.821\n",
            "7.0: 0.856\n",
            "8.0: 0.933\n",
            "9.0: 0.862\n",
            "10.0: 0.848\n",
            "11.0: 0.931\n",
            "\n",
            "Average recall over all classes: 0.794\n",
            "\n",
            "\n",
            "F1 score for each class:\n",
            "0.0: 0.744\n",
            "1.0: 0.797\n",
            "2.0: 0.768\n",
            "3.0: 0.794\n",
            "4.0: 0.746\n",
            "5.0: 0.815\n",
            "6.0: 0.818\n",
            "7.0: 0.843\n",
            "8.0: 0.859\n",
            "9.0: 0.825\n",
            "10.0: 0.793\n",
            "11.0: 0.882\n",
            "\n",
            "Average F1 score over all classes: 0.807\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}